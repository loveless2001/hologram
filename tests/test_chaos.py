"""
Chaos Testing Suite for Hologram
Generated by Chaos Engine V3

Run with: pytest tests/test_chaos.py -v --count=100
Requires: pytest-repeat, pytest-xdist
"""

import pytest
import threading
import time
import numpy as np
from pathlib import Path
from hologram.store import VectorIndex, MemoryStore, Trace
from hologram.gravity import Gravity
from hologram.api import Hologram


class TestConcurrentVectorIndex:
    """Test race conditions in VectorIndex"""
    
    def test_concurrent_upsert_corruption(self):
        """
        CHAOS TEST: Concurrent upserts should not corrupt index
        Expected: RuntimeError or correct state
        Current: Silent corruption (indices/keys misaligned)
        Risk Score: 0.95 (CRITICAL)
        """
        index = VectorIndex(dim=128, use_gpu=False)
        errors = []
        
        def worker(thread_id, count=50):
            try:
                for i in range(count):
                    key = f"thread{thread_id}_item{i}"
                    vec = np.random.rand(128).astype('float32')
                    index.upsert(key, vec)
            except Exception as e:
                errors.append((thread_id, str(e)))
        
        threads = [threading.Thread(target=worker, args=(i,)) for i in range(10)]
        for t in threads:
            t.start()
        for t in threads:
            t.join()
        
        # Verify integrity
        assert len(errors) == 0, f"Errors during upsert: {errors}"
        assert index.index.ntotal == len(index.id_to_key), \
            f"Index corruption: {index.index.ntotal} vectors but {len(index.id_to_key)} keys"
        
        # Verify search correctness
        for i in range(10):
            for j in range(50):
                key = f"thread{i}_item{j}"
                assert key in index.id_to_key, f"Missing key: {key}"
    
    def test_concurrent_search_during_upsert(self):
        """
        CHAOS TEST: Searches during concurrent upserts
        Expected: Either get results or raise error cleanly
        Current: May return partial/corrupted results
        Risk Score: 0.85 (CRITICAL)
        """
        index = VectorIndex(dim=128, use_gpu=False)
        stop_flag = threading.Event()
        search_errors = []
        
        def upserter():
            for i in range(200):
                index.upsert(f"item{i}", np.random.rand(128).astype('float32'))
                time.sleep(0.001)
        
        def searcher():
            while not stop_flag.is_set():
                try:
                    query = np.random.rand(128).astype('float32')
                    results = index.search(query, top_k=5)
                    # Verify all returned keys exist
                    for key, score in results:
                        assert key in index.id_to_key
                except Exception as e:
                    search_errors.append(str(e))
        
        t_upsert = threading.Thread(target=upserter)
        t_search = threading.Thread(target=searcher)
        
        t_upsert.start()
        t_search.start()
        t_upsert.join()
        stop_flag.set()
        t_search.join()
        
        assert len(search_errors) == 0, f"Search errors: {search_errors}"


class TestConcurrentGravity:
    """Test race conditions in Gravity field"""
    
    def test_concurrent_add_concept_crash(self):
        """
        CHAOS TEST: Concurrent add_concept() should not crash
        Expected: Clean error or correct execution
        Current: RuntimeError: dict changed size during iteration
        Risk Score: 0.92 (CRITICAL)
        """
        gravity = Gravity(dim=64)
        errors = []
        
        def worker(thread_id, count=30):
            try:
                for i in range(count):
                    name = f"concept_{thread_id}_{i}"
                    text = f"test concept {thread_id} {i}"
                    gravity.add_concept(name, text=text)
            except Exception as e:
                errors.append((thread_id, type(e).__name__, str(e)))
        
        threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]
        for t in threads:
            t.start()
        for t in threads:
            t.join()
        
        # Check for RuntimeError: dict changed size
        dict_errors = [e for e in errors if 'dict changed size' in e[2]]
        assert len(dict_errors) == 0, f"Dict iteration errors: {dict_errors}"
        
        # Verify all concepts were added
        expected_concepts = 5 * 30
        actual_concepts = len(gravity.concepts)
        # May be less due to race conditions, but should not crash
        assert actual_concepts > 0, "No concepts added"
    
    def test_decay_during_add_concept(self):
        """
        CHAOS TEST: step_decay() during add_concept() causes corruption
        Expected: Atomic operations or proper locking
        Current: Silent semantic field corruption
        Risk Score: 0.68 (HIGH)
        """
        gravity = Gravity(dim=64)
        
        # Pre-populate
        for i in range(50):
            gravity.add_concept(f"base_{i}", text=f"concept {i}")
        
        stop_flag = threading.Event()
        corruption_detected = []
        
        def adder():
            try:
                for i in range(100):
                    gravity.add_concept(f"new_{i}", text=f"new concept {i}")
                    time.sleep(0.001)
            except Exception as e:
                corruption_detected.append(('adder', str(e)))
        
        def decayer():
            try:
                while not stop_flag.is_set():
                    gravity.step_decay(steps=1)
                    time.sleep(0.005)
            except Exception as e:
                corruption_detected.append(('decayer', str(e)))
        
        t_add = threading.Thread(target=adder)
        t_decay = threading.Thread(target=decayer)
        
        t_add.start()
        t_decay.start()
        t_add.join()
        stop_flag.set()
        t_decay.join()
        
        # Should not crash
        assert len(corruption_detected) == 0, f"Corruption detected: {corruption_detected}"
        
        # Verify semantic coherence (basic sanity check)
        matrix = gravity.get_matrix()
        assert matrix.shape[0] > 0, "Gravity field is empty"
        assert not np.any(np.isnan(matrix)), "NaN values in concept vectors"


class TestMemoryStoreConcurrency:
    """Test MemoryStore composite operations"""
    
    def test_concurrent_add_trace_atomicity(self):
        """
        CHAOS TEST: add_trace() should be atomic
        Expected: Trace added to all components or none
        Current: Partial failures leave inconsistent state
        Risk Score: 0.75 (HIGH)
        """
        store = MemoryStore(vec_dim=128)
        errors = []
        
        def worker(thread_id, count=50):
            try:
                for i in range(count):
                    trace_id = f"t{thread_id}_{i}"
                    trace = Trace(
                        trace_id=trace_id,
                        kind="text",
                        content=f"content {thread_id} {i}",
                        vec=np.random.rand(128).astype('float32')
                    )
                    store.add_trace(trace)
            except Exception as e:
                errors.append((thread_id, str(e)))
        
        threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]
        for t in threads:
            t.start()
        for t in threads:
            t.join()
        
        assert len(errors) == 0, f"Errors: {errors}"
        
        # Verify consistency: all traces should be in dict, index, and sim
        for trace_id in store.traces:
            assert trace_id in store.index.id_to_key, f"Trace {trace_id} not in index"
            assert trace_id in store.sim.concepts, f"Trace {trace_id} not in gravity"


class TestAPIConcurrency:
    """Test Hologram API under concurrent load"""
    
    def test_concurrent_add_search(self):
        """
        CHAOS TEST: Concurrent adds and searches
        Expected: Correct search results
        Current: May return wrong traces due to index corruption
        Risk Score: 0.95 (CRITICAL)
        """
        holo = Hologram.init(use_clip=False, use_gravity=False)
        search_errors = []
        added_traces = []
        
        def adder(thread_id):
            for i in range(30):
                content = f"thread {thread_id} message {i}"
                trace_id = holo.add_text("test_glyph", content)
                added_traces.append((trace_id, content))
        
        def searcher():
            for _ in range(50):
                try:
                    results = holo.search_text("message", top_k=5)
                    # Verify all results are valid
                    for trace, score in results:
                        assert trace.trace_id in [t[0] for t in added_traces], \
                            f"Search returned unknown trace: {trace.trace_id}"
                except Exception as e:
                    search_errors.append(str(e))
                time.sleep(0.01)
        
        t_add = [threading.Thread(target=adder, args=(i,)) for i in range(3)]
        t_search = [threading.Thread(target=searcher) for _ in range(2)]
        
        for t in t_add + t_search:
            t.start()
        for t in t_add + t_search:
            t.join()
        
        assert len(search_errors) == 0, f"Search errors: {search_errors}"


class TestEdgeCases:
    """Test edge cases and boundary conditions"""
    
    def test_empty_index_search(self):
        """Edge case: Search on empty index"""
        index = VectorIndex(dim=128, use_gpu=False)
        results = index.search(np.random.rand(128).astype('float32'), top_k=5)
        assert results == []
    
    def test_very_long_text(self):
        """Edge case: Very long text (potential CLIP failure)"""
        holo = Hologram.init(use_clip=False)
        long_text = "word " * 10000  # 10k words
        trace_id = holo.add_text("test", long_text)
        assert trace_id is not None
    
    def test_negative_mass_after_decay(self):
        """Edge case: Mass decay leading to negative values"""
        gravity = Gravity(dim=64, mass_decay=0.5)
        gravity.add_concept("test", text="test")
        
        for _ in range(20):
            gravity.step_decay(steps=10)
        
        concept = gravity.concepts["test"]
        assert concept.mass >= 0, f"Negative mass: {concept.mass}"
    
    def test_duplicate_trace_id(self):
        """Edge case: Duplicate trace_id overwrites"""
        store = MemoryStore(vec_dim=128)
        
        trace1 = Trace("dup", "text", "original", np.ones(128, dtype=np.float32))
        trace2 = Trace("dup", "text", "overwrite", np.zeros(128, dtype=np.float32))
        
        store.add_trace(trace1)
        store.add_trace(trace2)
        
        retrieved = store.get_trace("dup")
        # Currently overwrites - should this warn?
        assert retrieved.content == "overwrite"


# Mutation Tests
class TestMutationCoverage:
    """Mutation testing for critical functions"""
    
    def test_upsert_without_normalize(self):
        """What if vectors aren't normalized?"""
        index = VectorIndex(dim=128, use_gpu=False)
        vec = np.array([1000.0] * 128, dtype='float32')  # Unnormalized
        index.upsert("test", vec)
        
        results = index.search(vec, top_k=1)
        assert len(results) == 1
        assert results[0][0] == "test"
    
    def test_gravity_encode_empty_string(self):
        """What if encoding empty string?"""
        gravity = Gravity(dim=64)
        vec = gravity.encode("")
        assert vec.shape == (64,)
        assert not np.any(np.isnan(vec))


if __name__ == "__main__":
    print("ðŸ”¥ Chaos Testing Suite for Hologram ðŸ”¥")
    print("Run with: pytest tests/test_chaos.py -v")
    print("For stress test: pytest tests/test_chaos.py --count=100")
